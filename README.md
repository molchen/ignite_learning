ignite学习记录

ignite 客户端url:
https://dbeaver.io/download/

ignite homepage:
https://ignite.apache.org/

some useful url
Binary object format:
https://cwiki.apache.org/confluence/display/IGNITE/Binary+object+format

Complete Discontinuation of IGFS and Hadoop Accelerator:
http://apache-ignite-developers.2346864.n4.nabble.com/DISCUSSION-Complete-Discontinuation-of-IGFS-and-Hadoop-Accelerator-td42282.html#a42326

Ignite的集群部署:
https://my.oschina.net/liyuj/blog/651036?p=1

搭建第一个Ignite集群时的注意事项:
https://my.oschina.net/liyuj/blog/3028514

CentOs7如何搭建Ignite单机及集群:
https://blog.csdn.net/weixin_43735682/article/details/94179036

ubuntu 14.04 install mongodb:
https://docs.mongodb.com/v3.2/tutorial/install-mongodb-on-ubuntu/#import-the-public-key-used-by-the-package-management-system

ubuntu 14.04 install nodejs:
https://stackoverflow.com/questions/34974535/install-latest-nodejs-version-in-ubuntu-14-04/39326989

Working With Hadoop: localhost: Error: JAVA_HOME is not set:
https://stackoverflow.com/questions/14325594/working-with-hadoop-localhost-error-java-home-is-not-set

java+mysql(blob类型)图片存取：
https://blog.csdn.net/qq_40424244/article/details/82850026

Hadoop: Setting up a Single Node Cluster:
https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html#Standalone_Operation

java.io.FileNotFoundException com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-api.jar:
https://stackoverflow.com/questions/43328022/spring-boot-embedded-tomcat-dependency-throws-exception-on-startup

org.apache.hadoop.ipc.remoteexception(org.apache.hadoop.security.accesscontrolexception:
https://community.cloudera.com/t5/Support-Questions/Permission-denied-user-root-access-WRITE-inode-quot-user/td-p/4943

Apache Ignite Cluster Together With Spring Boot:
https://dzone.com/articles/apache-ignite-cluster-together-with-spring-boot

issiues: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[172.20.10.9:50010,DS-7227115d-1c74-452d-be29-c9d800f9919f,DISK]], original=[DatanodeInfoWithStorage[172.20.10.9:50010,DS-7227115d-1c74-452d-be29-c9d800f9919f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration:
https://community.cloudera.com/t5/Community-Articles/Write-or-Append-failures-in-very-small-Clusters-under-heavy/ta-p/245446
